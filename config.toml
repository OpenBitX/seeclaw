[llm]
active_provider = "zhipu"

[llm.providers.openai]
display_name = "OpenAI"
api_base = "https://api.openai.com/v1/chat/completions"
model = "gpt-4o"
temperature = 0.2
api_key = ""

[llm.providers.deepseek]
display_name = "DeepSeek"
api_base = "https://api.deepseek.com/v1/chat/completions"
model = "deepseek-chat"
temperature = 0.1
api_key = ""

[llm.providers.zhipu]
display_name = "智谱 GLM"
api_base = "https://open.bigmodel.cn/api/paas/v4/chat/completions"
model = "glm-4.6v"
temperature = 0.1
api_key = ""

[llm.providers.qwen]
display_name = "阿里云 Qwen"
api_base = "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions"
model = "qwen-vl-max"
temperature = 0.1
api_key = ""

[llm.providers.openrouter]
display_name = "OpenRouter"
api_base = "https://openrouter.ai/api/v1/chat/completions"
model = "anthropic/claude-3.5-sonnet"
temperature = 0.2
api_key = ""

[llm.providers.claude]
display_name = "Anthropic Claude"
api_base = "https://api.anthropic.com/v1/messages"
model = "claude-opus-4-5"
temperature = 0.2
api_key = ""

[llm.roles.routing]
provider = "zhipu"
model = "glm-4-flash"
stream = false

[llm.roles.chat]
provider = "zhipu"
model = "glm-4-flash"
stream = true

[llm.roles.tools]
provider = "zhipu"
model = "glm-4.6v"
stream = true

[llm.roles.vision]
provider = "zhipu"
model = "glm-4.6v"
stream = true

[safety]
allow_terminal_commands = false
allow_file_operations = false
require_approval_for = [
    "execute_terminal",
    "file_delete",
    "install_package",
    "mcp_call",
]
max_consecutive_failures = 5
max_loop_duration_minutes = 0

[prompts]
tools_file = "prompts/tools/builtin.json"
system_template = "prompts/system/agent_system.md"
experience_summary_template = "prompts/system/experience_summary.md"

[[mcp.servers]]
name = "filesystem"
command = "npx"
args = [
    "-y",
    "@modelcontextprotocol/server-filesystem",
    "./workspace",
]
enabled = false

[perception]
# Number of grid rows and columns for the SoM overlay (4-26).
# Only used as fallback when YOLO detection produces no results.
grid_n = 12

# Path to YOLOv8/YOLO11 ONNX model.
# - "models/gpa_gui_detector.onnx" : Salesforce GPA-GUI-Detector (recommended, single-class UI element detection)
# - "models/yolov8n.onnx"          : Generic COCO 80-class (fallback)
# Run `uv run python scripts/download_gui_detector.py` to download the GUI model.
yolo_model_path = "models/gpa_gui_detector.onnx"

# YOLO confidence threshold (0.0–1.0). Lower = more detections, more noise.
# GPA-GUI-Detector works well with 0.05–0.15; COCO model needs 0.3+.
confidence_threshold = 0.05

# NMS IoU threshold (0.0–1.0). Higher = allow more overlapping boxes.
# GPA-GUI-Detector recommended: 0.5–0.7.
iou_threshold = 0.5

# Enable YOLO-based UI element detection.
# Falls back to SoM grid if model file is missing.
use_yolo = true

# Enable Windows UI Automation for additional element info (names, types).
# Temporarily disabled — UIA boxes overlap heavily and cause visual clutter.
enable_ui_automation = false

# Enable focus-crop second pass: crops and upscales the target region
# for more precise VLM identification. Adds ~1s latency per step.
enable_focus_crop = false

# Custom YOLO class names. If empty, auto-detects from model:
# - Single class ["icon"] for GPA-GUI-Detector
# - 80 COCO classes for generic YOLOv8n
class_names = ["icon"]
